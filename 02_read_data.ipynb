{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp read_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the data\n",
    "\n",
    "> This notebook covers reading and cleaning the Reddit data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from glob import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_fpaths(LEX, CORPUS_DIR='/Volumes/qjd/promo/SocEmb/data/psaw/'):\n",
    "    lex_path = f'{CORPUS_DIR}{LEX}' + \"/*.csv\"\n",
    "    fpaths = glob(lex_path)\n",
    "    return fpaths    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpaths = get_fpaths('Anglo-Saxon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def read_files(fpaths):\n",
    "    dfs = []\n",
    "    for fp in fpaths:\n",
    "        df = pd.read_csv(\n",
    "            fp,\n",
    "            usecols=['id', 'created_utc', 'subreddit', 'body'],\n",
    "        )\n",
    "        dfs.append(df)\n",
    "    df = pd.concat(\n",
    "        dfs,\n",
    "        axis=0,\n",
    "        ignore_index=True\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_files(fpaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 138932 entries, 0 to 138931\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   body         138928 non-null  object\n",
      " 1   created_utc  138928 non-null  object\n",
      " 2   id           138925 non-null  object\n",
      " 3   subreddit    138925 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 4.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def parse_dates(df):\n",
    "    df['created_utc'] = pd.to_datetime(df['created_utc'], errors='coerce')\n",
    "    df.sort_values('created_utc', inplace=True)\n",
    "    df.dropna(subset=['created_utc'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = parse_dates(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 138925 entries, 117981 to 117982\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   body         138925 non-null  object        \n",
      " 1   created_utc  138925 non-null  datetime64[ns]\n",
      " 2   id           138925 non-null  object        \n",
      " 3   subreddit    138925 non-null  object        \n",
      "dtypes: datetime64[ns](1), object(3)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_processing.ipynb.\n",
      "Converted 01_installation.ipynb.\n",
      "Converted 02_read_data.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "socembed",
   "language": "python",
   "name": "socembed"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
