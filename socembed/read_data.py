# AUTOGENERATED! DO NOT EDIT! File to edit: 02_read_data.ipynb (unless otherwise specified).

__all__ = ['CREDS', 'get_fpaths', 'read_files', 'parse_dates']

# Cell
from glob import glob
import pandas as pd

import os
from google.cloud import storage

# Cell
CREDS = f'{os.getcwd()}/google-drive-d2e64a7dbc90.json'
%env GOOGLE_APPLICATION_CREDENTIALS=$CREDS

# Cell
def get_fpaths(LEX, CORPUS_DIR='/Volumes/qjd/promo/SocEmb/data/psaw/', source='remote', bucket_name='socemb'):
    if source == 'remote':
        client = storage.Client()
        blobs = [blob for blob in client.list_blobs(bucket_name, prefix=f'comments/{LEX}')]
        fpaths = [f'gs://{bucket_name}/{blob.name}' for blob in blobs]
    if source == 'local':
        lex_path = f'{CORPUS_DIR}{LEX}' + "/*.csv"
        fpaths = glob(lex_path)
    return fpaths

# Cell
def read_files(fpaths):
    dfs = []
    for fp in fpaths:
        df = pd.read_csv(
            fp,
            usecols=['id', 'created_utc', 'subreddit', 'body'],
        )
        dfs.append(df)
    df = pd.concat(
        dfs,
        axis=0,
        ignore_index=True
    )
    return df

# Cell
def parse_dates(df):
    df['created_utc'] = pd.to_datetime(df['created_utc'], errors='coerce')
    df.sort_values('created_utc', inplace=True)
    df.dropna(subset=['created_utc'], inplace=True)
    return df